{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This Notebook is explains how `api_request_script.py` works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import requests\n",
    "import datetime\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I collect command line arguments to get:\n",
    "   1. sys.argv[1] is the API request (string) I'm making. Let's call it arg1 in this tutorial.\n",
    "   2. sys.argv[2] is the name (string) of the pickled dat file I'm exporting. Similarly, we'll call it arg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arg1 = 'https://newsapi.org/v2/everything?q=(BTC OR bitcoin)&from=2018-01-01&to=2018-01-10&language=en&sortBy=popularity&apiKey=6d00cdefd3bc4ee38f8a7af69ac5bec4'\n",
    "arg2 = '2018-01-01_2018-01-10.dat'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These classes help me make the API request, format the data, and collect several pages of a request if possible. The comments give a bit more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"This class converts a dict to nested objects\"\"\"\n",
    "\n",
    "class Struct(object):\n",
    "    \"\"\"\n",
    "    Attributes will depend on the structure of object. \n",
    "    If we keep calling the 'everything' newsapi, then the attributes will be:\n",
    "    \n",
    "                    articles: A list of articles, each with their own objects\n",
    "                    status: Status of request, should be 'ok'\n",
    "                    totalResults: The total number of results available for the request, will need\n",
    "                                  to use the &page= parameter to get these as only 20 articles are\n",
    "                                  returned per request.\n",
    "                                  \n",
    "    Resource: https://stackoverflow.com/questions/1305532/convert-python-dict-to-object\n",
    "    \"\"\"\n",
    "    def __init__(self, data):\n",
    "        for name, value in data.items():\n",
    "            setattr(self, name, self._wrap(value))\n",
    "\n",
    "    def _wrap(self, value):\n",
    "        if isinstance(value, (tuple, list, set, frozenset)): \n",
    "            return type(value)([self._wrap(v) for v in value])\n",
    "        else:\n",
    "            return Struct(value) if isinstance(value, dict) else value\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "General class to aggregate all useful objects. \n",
    "Could customize, e.g. change structure of get_raw_data to affect data object\n",
    "\"\"\"\n",
    "\n",
    "class myclass(object):\n",
    "    \"\"\"\n",
    "    Attributes:\n",
    "                call: The url sent to newsapi\n",
    "                raw_data: The dictionary returned when requesting call\n",
    "    \"\"\"\n",
    "    \n",
    "    def get_raw_data(self,call):\n",
    "        r = requests.get(call).json()\n",
    "        \n",
    "        for i in r['articles']:\n",
    "            #don't care about author or image url\n",
    "            del i['author'] \n",
    "            del i['urlToImage']\n",
    "            #convert publishing data/time to be by day\n",
    "            t = datetime.datetime.strptime(i['publishedAt'], \"%Y-%m-%dT%H:%M:%S%fZ\")\n",
    "            nt = t.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "            i['publishedAt'] = str(nt)\n",
    "            #collect only the name of the source, not id\n",
    "            i['source'] = i['source']['name']\n",
    "        \n",
    "        return r\n",
    "    \n",
    "    def __init__(self,call):\n",
    "        self.call = call\n",
    "        self.data = Struct(self.get_raw_data(call))\n",
    "        self.data.n_pages = self.data.totalResults/20\n",
    "        \n",
    "    \"\"\"\n",
    "    Takes call and paginates over user input number of pages to provide a list of \n",
    "    lists made up of articles\n",
    "    \"\"\"\n",
    "        \n",
    "    def paginate(self,n):\n",
    "        #If page argument already exists in call, remove it\n",
    "        fp = self.call.find('&page=')\n",
    "        if fp > 0:\n",
    "            l = [x for x, v in enumerate(self.call) if v == '&']\n",
    "            l.append(len(self.call))\n",
    "            nxt = l[next(x[0] for x in enumerate(l) if x[1] > fp)]\n",
    "            base_call = self.call[:fp] + self.call[nxt:]\n",
    "        else:\n",
    "            base_call = self.call\n",
    "        \n",
    "        #loop over pages and add article objects to list\n",
    "        articles_list = []\n",
    "        \n",
    "        for i in range(1,n+1):\n",
    "            new_call = base_call + \"&page=\" + str(i)\n",
    "            d = Struct(self.get_raw_data(new_call))\n",
    "            articles_list.extend(d.articles)\n",
    "            \n",
    "        return articles_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n =  myclass(arg1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the API request look like after I used `myclass()`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'articles': [<__main__.Struct at 0x7f3cf80fcd30>,\n",
       "  <__main__.Struct at 0x7f3cf80fcc50>,\n",
       "  <__main__.Struct at 0x7f3cf80fc9e8>,\n",
       "  <__main__.Struct at 0x7f3cf80fcb70>,\n",
       "  <__main__.Struct at 0x7f3cf80fca20>,\n",
       "  <__main__.Struct at 0x7f3cff00f438>,\n",
       "  <__main__.Struct at 0x7f3d0165de80>,\n",
       "  <__main__.Struct at 0x7f3cf8ce05f8>,\n",
       "  <__main__.Struct at 0x7f3cf8ce0cc0>,\n",
       "  <__main__.Struct at 0x7f3cf8ce02b0>,\n",
       "  <__main__.Struct at 0x7f3cf8ce0d68>,\n",
       "  <__main__.Struct at 0x7f3cf8ce0d30>,\n",
       "  <__main__.Struct at 0x7f3cf8ce03c8>,\n",
       "  <__main__.Struct at 0x7f3cf8ce0518>,\n",
       "  <__main__.Struct at 0x7f3cf8ce0e10>,\n",
       "  <__main__.Struct at 0x7f3cf8ce01d0>,\n",
       "  <__main__.Struct at 0x7f3cf8ce06a0>,\n",
       "  <__main__.Struct at 0x7f3cf8ce0438>,\n",
       "  <__main__.Struct at 0x7f3cf8ce04e0>,\n",
       "  <__main__.Struct at 0x7f3cf811b4a8>],\n",
       " 'n_pages': 265.15,\n",
       " 'status': 'ok',\n",
       " 'totalResults': 5303}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.data.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `data.n_pages` to get the number of pages we should collect (potential input to `.paginate()`). I provide some logic here so that the user doesn't accidentally exceed their 1000 request per day limit :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if n.data.n_pages > 900:\n",
    "    p = 900\n",
    "else:\n",
    "    p = int(n.data.n_pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can collect all pages of articles in one list from our API request. For now I'll just collect 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = n.paginate(10)\n",
    "len(l)  #should be 20 * p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we need to store this list of objects for later use! We'll pickle it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(arg2, \"wb\") as f:\n",
    "    pickle.dump(l, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example command line call:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python3 api_request_script.py 'https://newsapi.org/v2/everything?q=(BTC OR bitcoin)&from=2018-01-01&to=2018-01-10&language=en&sortBy=popularity&apiKey=6d00cdefd3bc4ee38f8a7af69ac5bec4' '2018-01-01_2018-01-10.dat'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
